{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f3b0e3",
   "metadata": {},
   "source": [
    "## FFF Vision - Hough Transform Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b53245f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b53245f",
    "outputId": "0d533be0-a635-44cb-8c50-a7a2818cfae5"
   },
   "outputs": [],
   "source": [
    "#Importing all necessary packages.\n",
    "import numpy as np\n",
    "import cv2\n",
    "print('OpenCV version: '+cv2.__version__)\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa76b5e",
   "metadata": {
    "id": "1fa76b5e"
   },
   "outputs": [],
   "source": [
    "#used for time calculation.\n",
    "start = time.perf_counter()\n",
    "#Reading the folder where the videos are saved.\n",
    "SRC_FOLDER = r\"D:\\Pensulvaniya state project\\FFF Vision - OpenCV [External]\\Vidseos\\\\\"\n",
    "#reading the vieo_Time_Stamp from device.\n",
    "df_vidTimes = pd.read_excel(SRC_FOLDER + \"Video_Timestamps_1.xlsx\")\n",
    "df_vidTimes.drop(df_vidTimes.columns[0],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b5f06",
   "metadata": {
    "id": "d77b5f06"
   },
   "outputs": [],
   "source": [
    "#Function for image perspective correction.\n",
    "def perspCorrection(img,pt1,pt2,pt3,pt4,scale_width,scale_height):\n",
    "    \n",
    "    input_pts = np.float32([pt1,pt2,pt3,pt4])\n",
    "    output_pts = np.float32([[0,0],[scale_width-1,0],[0,scale_height-1],[scale_width-1,scale_height-1]])\n",
    "    M = cv2.getPerspectiveTransform(input_pts,output_pts)\n",
    "    #saves the perspective corrected image to a varibale.\n",
    "    imgPersp = cv2.warpPerspective(img,M,(scale_width, scale_height)) \n",
    "    #grayscale conversion.\n",
    "    imgGrayPersp = cv2.cvtColor(imgPersp, cv2.COLOR_BGR2GRAY)            \n",
    "    \n",
    "    return [imgPersp,imgGrayPersp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf13a3c3",
   "metadata": {
    "id": "cf13a3c3"
   },
   "outputs": [],
   "source": [
    "# function for hough transform and width calculation\n",
    "def hough(gray_image,mm_per_pixel):\n",
    "    \n",
    "    # Canny edge detection\n",
    "    edges = cv2.Canny(gray_image, 50, 150, apertureSize=3)\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi/180, 150)\n",
    "    for r_theta in lines:\n",
    "        arr = np.array(r_theta[0], dtype=np.float64)\n",
    "        r, theta = arr\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*r\n",
    "        y0 = b*r\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        cv2.line(edges, (x1, y1), (x2, y2), 125, 2)\n",
    "    \n",
    "    # Extrusion width calculation\n",
    "    indices = np.where(edges == 125)\n",
    "    y_indices = indices[1]\n",
    "    avg = np.mean(indices[1])\n",
    "    LEdges = y_indices[np.where(y_indices < avg)]\n",
    "    REdges = y_indices[np.where(y_indices > avg)]\n",
    "    width_px = np.abs(np.mean(REdges)-np.mean(LEdges))\n",
    "    width_in_mm = mm_per_pixel * width_px\n",
    "    \n",
    "    text = str(width_in_mm) + ' mm'\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    org = (50,50)\n",
    "    fontScale = 1\n",
    "    color = (255, 0, 0)\n",
    "    thickness = 2\n",
    "    img_color = cv2.putText(imgGrayPersp, text, org, font,fontScale, color, thickness)\n",
    "\n",
    "    \n",
    "    return [width_px, width_in_mm, img_color, edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d52e6b",
   "metadata": {
    "id": "54d52e6b"
   },
   "outputs": [],
   "source": [
    "# Remove # for below code to save the path of folder in which images for analysis is to be saved\n",
    "#imganalysis_path = SRC_FOLDER + \"Results/Run-2\"\n",
    "\n",
    "#function for storing images for analysis, need to call this function from recursive function.\n",
    "\n",
    "def image_for_analysis(imganalysis_path,layer,speed,frameCount,edges,imgcolor):\n",
    "    \n",
    "    #for storing perspective corrected grayscale images.\n",
    "    cv2.imwrite(imganalysis_path + '/' + str(layers) + \"/\" + str(speeds) + \"/Gray/\" +  \"pCorr\" + str(frameCount) + \".jpg\", imgGrayPersp)\n",
    "    \n",
    "    #for storing thersholded images.                       \n",
    "    cv2.imwrite(imganalysis_path +  '/' + str(layers) + \"/\" + str(speeds) + \"/Thresholded Images/\" + \"thresh\" + str(frameCount) + \".jpg\", thersholded_image)\n",
    "    \n",
    "    #for storing output images of  median blur function.                     \n",
    "    cv2.imwrite(imganalysis_path +  '/' + str(layers) + \"/\" + str(speeds) + \"/median blur/\" + \"medianblur\" + str(frameCount) + \".jpg\", medianblr)\n",
    "    \n",
    "    #for storing output images of  morphological operations(dilation and erosion).                     \n",
    "    cv2.imwrite(imganalysis_path +  '/' + str(layers) + \"/\" + str(speeds) + \"/Erosion and Dilation/\" + \"morphOps\" + str(frameCount) + \".jpg\", cloperation)\n",
    "    \n",
    "    #for storing canny images with detected edges.                         \n",
    "    cv2.imwrite(imganalysis_path +  '/' + str(layer) + \"/\" + str(speed) + \"/Canny/\" + \"Canny\" + str(frameCount) + \".jpg\", edges)\n",
    "    \n",
    "    #for storing the ROI selected images.                        \n",
    "    #cv2.imwrite(imganalysis_path +  '/' + str(layers) + \"/\" + str(speeds) + \"/ROI/\" + \"ROI\" + str(frameCount) + \".jpg\", bottom_image)    \n",
    "    \n",
    "    #for storing the images with labeled width measures.\n",
    "    cv2.imwrite(imganalysis_path +  '/' + str(layer) + \"/\" + str(speed) + \"/Vision Measurements/\" + \"wImg\" + str(frameCount) + \".jpg\", imgcolor)\n",
    "    \n",
    "    return None\n",
    "#This function returns nothing since it only save images to respective folders in system.\n",
    "#There should be image folders as mentioned in the save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1053a06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1053a06",
    "outputId": "b4215425-8031-4aea-ad94-96cffaf8ac98"
   },
   "outputs": [],
   "source": [
    "#Main program\n",
    "num_layers = 20\n",
    "max_speed = 50\n",
    "layers = list(range(5,num_layers+1))\n",
    "speeds = list(range(10,max_speed+10,10))\n",
    "frame_skip_start = [32,20,11,15,13] \n",
    "\n",
    "vidCount = 0\n",
    "img_debug = False \n",
    "\n",
    "w_result_columns=['Layer','vR','Frame','ActualTimestamp','Edge Distance in Pixel','w_Vision']\n",
    "frame_summary_columns = ['Layer','vR','Start_TS','End_TS','Total_Frames','Per_Frames_Skipped','Skipped_Frames']\n",
    "lst = []\n",
    "lst_skip_frames = []\n",
    "lst_frame_summary = []\n",
    "\n",
    "pt1 = [192.30,343.00]  \n",
    "pt2 = [1079.0,379.80]  \n",
    "pt3 = [153.50,571.90] \n",
    "pt4 = [1107.10,611.70] \n",
    "\n",
    "scale_width = round(11.7348*200) \n",
    "scale_height = round(6.35*200)   \n",
    "\n",
    "bStart = [655,925]\n",
    "bEnd = [1300,1270]\n",
    "fsize =9\n",
    "threshold_1 =30\n",
    "threshold_2 = 80\n",
    "mm_per_pixel = 0.004992138364779874\n",
    "\n",
    "\n",
    "for l in range(len(layers)):\n",
    "    for v in range(len(speeds)):\n",
    "        \n",
    "        lst = []\n",
    "        lst_skip_frames = []\n",
    "                \n",
    "        vidName = 'vid_l'+str(layers[l])+'_vR_'+str(speeds[v])+'.avi'\n",
    "        print('Processing video: ' + vidName)\n",
    "        \n",
    "        idx = df_vidTimes.index[(df_vidTimes.Layer==layers[l]) & (df_vidTimes.Speed==speeds[v])].to_list()[0]\n",
    "        start_TS = df_vidTimes.Start_Timestamp[idx]\n",
    "        end_TS = df_vidTimes.End_Timestamp[idx]\n",
    "        \n",
    "        print('video: {0} starts at {1} and ends at {2}'.format(vidName,start_TS,end_TS))\n",
    "        \n",
    "        srcVideo = SRC_FOLDER + vidName       \n",
    "        cap = cv2.VideoCapture(srcVideo)\n",
    "        numFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        print('video {0} has {1} frames'.format(vidName,numFrames))\n",
    "\n",
    "        if (cap.isOpened() == False):\n",
    "            print(\"Error reading video file. Exiting ...\")\n",
    "            exit(0)\n",
    "     \n",
    "            \n",
    "            \n",
    "        frameCount = 0\n",
    "\n",
    "        while(cap.isOpened()):\n",
    "    \n",
    "            frame_exists, frame = cap.read()\n",
    "               \n",
    "               \n",
    "            if frame_exists:\n",
    "                \n",
    "                frameCount = frameCount + 1\n",
    "                \n",
    "\n",
    "                if(frameCount >= frame_skip_start[v] and frameCount <= numFrames - 5): \n",
    "                    \n",
    "                    try:\n",
    "                                               \n",
    "\n",
    "                        # call function - correct perspective transform\n",
    "                        [imgPersp,imgGrayPersp] = perspCorrection(frame,pt1,pt2,pt3,pt4,scale_width,scale_height)\n",
    "                        \n",
    "                        \n",
    "\n",
    "                         #Hough Transformation\n",
    "                         # Extrusion width measurement\n",
    "                        [width_px, width_in_mm, imgcolor, edges] = hough(imgGrayPersp,mm_per_pixel) \n",
    "                        #cv2.imwrite(patha + str(layers[l]) + str(speeds[v]) + str(frameCount) + \".jpg\", imgcolor)\n",
    "      \n",
    "                        \n",
    "                        #Remove Comment line for below code , if images needs to be saved for analysing.\n",
    "                        #image_for_analysis(imganalysis_path,layers[l],speeds[v],frameCount,edges,imgcolor)\n",
    "\n",
    "                        # Calculate actual timestamp based on excel timestamps and frame number\n",
    "                        act_TS = start_TS+frameCount*(end_TS-start_TS)/numFrames\n",
    "\n",
    "                        # Store results in dataframe   \n",
    "                        lst.append([layers[l],speeds[v],frameCount,act_TS,width_px, width_in_mm])\n",
    "                        \n",
    "\n",
    "                        \n",
    "                    except ValueError as e:\n",
    "                        \n",
    "                        print('Unable to sucessfully process frame {0}, skipping . . .'.format(frameCount))\n",
    "                        print(e)\n",
    "                        # Calculate actual timestamp based on excel timestamps and frame number\n",
    "                        act_TS = start_TS+frameCount*(end_TS-start_TS)/numFrames\n",
    "                        # Store results in dataframe   \n",
    "                        lst.append([layers[l],speeds[v],frameCount,act_TS,np.nan,np.nan])\n",
    "                        lst_skip_frames.append([frameCount])\n",
    "\n",
    "                    except UnboundLocalError as u:\n",
    "                        print('Unable to sucessfully process frame {0}, skipping . . .'.format(frameCount))\n",
    "                        print(u)\n",
    "                        # Calculate actual timestamp based on excel timestamps and frame number\n",
    "                        act_TS = start_TS+frameCount*(end_TS-start_TS)/numFrames\n",
    "                        # Store results in dataframe   \n",
    "                        lst.append([layers[l],speeds[v],frameCount,act_TS,np.nan,np.nan])\n",
    "                        lst_skip_frames.append([frameCount])\n",
    "                        \n",
    "                    except TypeError as t:\n",
    "                        print('Unable to sucessfully process frame {0}, skipping . . .'.format(frameCount))\n",
    "                        print(\"Necessary lines are not detected in the frame\") \n",
    "                        # Calculate actual timestamp based on excel timestamps and frame number\n",
    "                        act_TS = start_TS+frameCount*(end_TS-start_TS)/numFrames\n",
    "                        # Store results in dataframe   \n",
    "                        lst.append([layers[l],speeds[v],frameCount,act_TS,np.nan,np.nan])\n",
    "                        lst_skip_frames.append([frameCount])\n",
    "\n",
    "            else:\n",
    "                \n",
    "                break       \n",
    "                   \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        print('Finished processing video: {0}'.format(vidName))\n",
    "        print('')\n",
    "        print('')\n",
    "        vidCount = vidCount + 1\n",
    "    \n",
    "        results = pd.DataFrame(lst,columns=w_result_columns)\n",
    "        # Save results to csv file\n",
    "        path = SRC_FOLDER + \"Results/Run-2/\" + 'l' + str(layers[l])+'_vR'+str(speeds[v])+\"results1.csv\"\n",
    "        results.to_csv(path)\n",
    "        lst_frame_summary.append([layers[l],speeds[v],start_TS,end_TS,numFrames,len(lst_skip_frames)/numFrames,lst_skip_frames])\n",
    "\n",
    "\n",
    "frame_summary_results = pd.DataFrame(lst_frame_summary,columns=frame_summary_columns)\n",
    "\n",
    "# Some more cleanup and data addition\n",
    "frame_summary_results[\"Video_Duration\"] = frame_summary_results[\"End_TS\"] - frame_summary_results[\"Start_TS\"] \n",
    "frame_summary_results[\"Video_Duration\"] = [x.total_seconds() for x in frame_summary_results[\"Video_Duration\"]]\n",
    "frame_summary_results[\"FPS\"] = frame_summary_results[\"Total_Frames\"]/frame_summary_results[\"Video_Duration\"]\n",
    "frame_summary_results[\"Total_Frames_Skipped\"] = [len(x) for x in frame_summary_results[\"Skipped_Frames\"]]\n",
    "\n",
    "# Re-oder columns\n",
    "frame_summary_results = frame_summary_results[[\"Layer\",\"vR\",\"Start_TS\",\"End_TS\",\"Video_Duration\",\"Total_Frames\",\"FPS\",\"Total_Frames_Skipped\",\"Per_Frames_Skipped\",\"Skipped_Frames\"]]\n",
    "\n",
    "#Writing to CSV\n",
    "path_summary = SRC_FOLDER + \"Results/Run-2/\"+ 'video_processing_summary.csv'\n",
    "frame_summary_results.to_csv(path_summary)\n",
    "    \n",
    "print('Processing of all videos completed successfully! Summary results saved at {0}'.format(summary_path))\n",
    "end = time.perf_counter() - start\n",
    "print('{:.6f}s for the calculation'.format(end))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "29a82d12d14dcb997693ed4527530de1a8a184a05e45a53f34d76fe516b426d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
